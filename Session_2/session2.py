# -*- coding: utf-8 -*-
"""Session2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p3G6Ezb1Munw7b6dWAeKGWQ3UhcCWz_c

# **Not an ideal network**

###Installs keras library for this session of colab and then Imports the Keras library
"""

# https://keras.io/
!pip install -q keras  
import keras ###Importing Keras library

"""###Importing features from Keras library. 

---

* Sequential allows us to create a layer by layer model.
* Flatten method singles out induvidual features.
* convolution layers method.
* Numpy utilities for keras.
* mnist dataset.
"""

import numpy as np

from keras.models import Sequential 
from keras.layers import Flatten 
from keras.layers import Convolution2D
from keras.utils import np_utils

from keras.datasets import mnist

"""###This will load the mnist data set


---

* mnist.load_data() returns two tuples of training data and test data along with their classes
"""

(X_train, y_train), (X_test, y_test) = mnist.load_data()

"""### Print the shape of the matrix and the image data using matplotlib"""

print (X_train.shape)
from matplotlib import pyplot as plt
# %matplotlib inline
plt.imshow(X_train[0])

"""### Reshape training and test data to 28x28"""

X_train = X_train.reshape(X_train.shape[0], 28, 28,1)
X_test = X_test.reshape(X_test.shape[0], 28, 28,1)

"""###Convert integer type data to float32 type and restrict data in betwwen 0-255 to 0-1 for both test and training data."""

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

y_train[:10]

# Convert 1-dimensional class arrays to 10-dimensional class matrices
Y_train = np_utils.to_categorical(y_train, 10)
Y_test = np_utils.to_categorical(y_test, 10)

Y_train[:10]

"""### Create a sequential convolutional model which will take an input of size 28x28x1"""

from keras.layers import Activation, MaxPooling2D

model = Sequential() 
model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) #Input 28x28
model.add(Convolution2D(64, 3, 3, activation='relu')) #input 26x26 receptive field 3
model.add(Convolution2D(128, 3, 3, activation='relu')) #input 24x24 receptive field 5

model.add(MaxPooling2D(pool_size=(2, 2))) #input 22x22 receptive field 7

model.add(Convolution2D(256, 3, 3, activation='relu')) #input 11x11 receptive field 14
model.add(Convolution2D(512, 3, 3, activation='relu')) #Input 9x9 receptive field 16
model.add(Convolution2D(1024, 3, 3, activation='relu')) #input 7x7 receptive field 18
model.add(Convolution2D(2048, 3, 3, activation='relu')) #input 5x5 receptive field 20
model.add(Convolution2D(10, 3, 3, activation='relu')) #input 3x3 receptive field 22

model.add(Flatten()) #input 1x1 receptive field 22
model.add(Activation('softmax')) #input 1x1 receptive field 22

model.summary()

"""### Compile the model"""

model.compile(loss='categorical_crossentropy',
             optimizer='adam',
             metrics=['accuracy'])

"""### Train the model on the traning set for 10 epochs"""

model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)

"""###Calculate the score"""

score = model.evaluate(X_test, Y_test, verbose=0)

"""###Print score"""

print(score)

"""###Predict the class for X_Test"""

y_pred = model.predict(X_test)

print(y_pred[:9])
print(y_test[:9])

"""### Why the model isn't training properly?
1. Jumping from 2048 channels to 10 channels causes a lot of information loss, and hence is not advisable. 
2.  Having a relu layer as a last layer is not advisable as if there are negetive values as the output of last layers, they'll become 0.
3.  Considering the output on the last layer, the penultimate convolution layer probably contained a a lot of negetive values which become 0 and when softmax function is applied on it, the resulting output becomes 0.1.
"""