# -*- coding: utf-8 -*-
"""Copy of S4_Third_DNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zgxz3IJRQ3tYJYIaLas0DfwG9NU4n7he

# **Import Libraries and modules**

###Import Keras libraries
"""

# https://keras.io/
!pip install -q keras
import keras

"""###Importing other libraries needed"""

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Add
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils

from keras.datasets import mnist

"""### Load pre-shuffled MNIST data into train and test sets"""

(X_train, y_train), (X_test, y_test) = mnist.load_data()

"""###Print the image dimensions and plot the image"""

print (X_train.shape)
from matplotlib import pyplot as plt
# %matplotlib inline
plt.imshow(X_train[0])

"""###reshape the training and testing datasets"""

X_train = X_train.reshape(X_train.shape[0], 28, 28,1)
X_test = X_test.reshape(X_test.shape[0], 28, 28,1)

"""###Convert integer type data to float32 type and restrict data in betwwen 0-255 to 0-1 for both test and training data"""

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

"""###Display first 10 elements in the trainign dataset"""

y_train[:10]

# Convert 1-dimensional class arrays to 10-dimensional class matrices
Y_train = np_utils.to_categorical(y_train, 10)
Y_test = np_utils.to_categorical(y_test, 10)

"""### Kernel normalization code"""

from keras.preprocessing.image import ImageDataGenerator



# report pixel means and standard deviations
print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))

# create generator that centers pixel values
datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)

# calculate the mean on the training dataset
datagen.fit(X_train)
print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))

# demonstrate effect on a single batch of samples 
iterator = datagen.flow(X_train, Y_train, batch_size=64)

# get a batch
batchX, batchy = iterator.next()


# pixel stats in the batch
print(batchX.shape, batchX.mean(), batchX.std())

# demonstrate effect on entire training dataset
iterator = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)

iterator_test = datagen.flow(X_test, Y_test, batch_size=len(X_test), shuffle=False)

batchX_test, batchy_test = iterator_test.next()

# get a batch
batchX, batchy = iterator.next()

# pixel stats in the batch
print(batchX.shape, batchX.mean(), batchX.std())
print(batchX_test.shape, batchy_test.shape)
print(batchy_test[:10])

"""#The DNN
### The network is designed with dropouts, one maxpooling and 7 convolution layers. 
### Changes:
* Added batchnormalization.
* Using a larger batch size.
* Changed the learning rate

###    Observations

   1. Slight increase in the accuracy, desired accuracy achived
   2.  Smaller epoch time: This is because of the increased batch size.
   3. The learning rate is slightly decreases in each epoch and this small change accumilates over time and makes significant difference.
"""

from keras.layers import Activation
from keras.layers import Dropout
from keras.layers import MaxPool2D
from keras.layers import BatchNormalization
from keras import regularizers

model = Sequential()
 
model.add(Convolution2D(32, 3, 3, input_shape=(28,28,1),kernel_regularizer = regularizers.l2(0.01))) #Will return 26x26x32
model.add(BatchNormalization()) #apply batch normalization
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(Convolution2D(16, 3, 3,kernel_regularizer = regularizers.l2(0.01))) #returns 24x24x16
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(Convolution2D(8, 3, 3,kernel_regularizer = regularizers.l2(0.01))) #returns 22x22x16
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(MaxPool2D(2,2)) #returns11x11x16

model.add(Convolution2D(10, 3, 3, kernel_regularizer = regularizers.l2(0.01))) #returns 9x9x10
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(Convolution2D(8, 3, 3, kernel_regularizer = regularizers.l2(0.01))) #7x7x10
model.add(BatchNormalization()) 
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(Convolution2D(8, 3, 3, kernel_regularizer = regularizers.l2(0.01))) #returs 5x5x8
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(Convolution2D(12,1,1,kernel_regularizer = regularizers.l2(0.01))) # returns 5x5x14


model.add(Convolution2D(10, 5, 5))  #returns 1x1x10


model.add(Flatten())  #Runs flatten operation on the image matrix 
model.add(Activation('softmax'))

"""### Outputs the summary of our model"""

model.summary()

"""### Compiles the model and create a checkpoint callback which remembers the best accuracy achived in the training phase."""

from keras.callbacks import ModelCheckpoint
from keras.callbacks import LearningRateScheduler

def scheduler(epoch, lr):
  return round(0.003 * 1/(1 + 0.3242 * epoch), 10)
  

model.compile(loss='categorical_crossentropy',optimizer='adam',
             metrics=['accuracy'])

checkpoint = ModelCheckpoint('model.best-accuracy.hdfs', save_best_only=True,monitor='val_acc')
callback_list=[checkpoint]
#callback_list.append(LearningRateScheduler(scheduler, verbose=1))

"""### training the model and alsoo validate the model at each epoch against test data."""

model.fit(batchX, batchy , batch_size=64, nb_epoch=40 , verbose=1, callbacks=callback_list, validation_data=(batchX_test,batchy_test))
#model.model.fit_generator(datagen.flow(X_train, y_train, batch_size=len(X_train)), steps_per_epoch=len(X_train), shuffle=False,epochs = 40)

"""### Load the best model that was saved and evalute the model against the test data and record the score."""

#model.load_weights('model.best-accuracy.hdfs')
from keras.models import load_model
model = load_model('model.best-accuracy.hdfs')
score = model.evaluate(batchX_test,batchy_test, verbose=0)

"""###Print  the score"""

print(score)

"""###Code to find out the misclassifeed images and print them on a grid"""

classified = model.predict_classes(batchX_test)#Predict the model with test data
misclassified_images = [] #stores index of the misclassifed images
mis_pos = 0 # index of misclasified images

def get_class(prediction):
  return 1 if prediction > 0.90 else 0 #if the prediction is less than 90% accuracy, consider if misclassified


for i in classified:
  res = get_class(i)
  if res == 0:
    misclassified_images.append(mis_pos)    #if the image is said to be misclassified, then store the index of it in misclasified_imagrs array
  mis_pos+=1

#plot the images whoch are misclassifed
f, axarr = plt.subplots(5,5)
pos = 0
for (x, y) in [(i, j) for i in range(0,5) for j in range(0,5)]:
  
  axarr[x,y].imshow(batchX_test[misclassified_images[pos]].reshape(28,28))
  pos+=1

"""###predict the output on test data"""

y_pred = model.predict(X_test)

from numpy import absolute
result = absolute(Y_test - y_pred)
for i in X_test[:25]:
  plt.imshow(i)

print(y_pred[:9])
print(y_test[:9])

layer_dict = dict([(layer.name, layer) for layer in model.layers])
print(layer_dict)

"""###This block of code shows us what the kernel sees in a particular layer that is passed to it and displays it.
###The textures and patterns that the kernel sees are printed in the output cell as shown.
"""

import numpy as np
from matplotlib import pyplot as plt
from keras import backend as K
# %matplotlib inline
# util function to convert a tensor into a valid image
def deprocess_image(x):
    # normalize tensor: center on 0., ensure std is 0.1
    x -= x.mean()
    x /= (x.std() + 1e-5)
    x *= 0.1

    # clip to [0, 1]
    x += 0.5
    x = np.clip(x, 0, 1)

    # convert to RGB array
    x *= 255
    #x = x.transpose((1, 2, 0))
    x = np.clip(x, 0, 255).astype('uint8')
    return x

def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), 
                      layer_name = 'conv2d_3'):
    layer_output = layer_dict[layer_name].output
    img_ascs = list()
    for filter_index in range(layer_output.shape[3]):
        # build a loss function that maximizes the activation
        # of the nth filter of the layer considered
        loss = K.mean(layer_output[:, :, :, filter_index])

        # compute the gradient of the input picture wrt this loss
        grads = K.gradients(loss, model.input)[0]

        # normalization trick: we normalize the gradient
        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)

        # this function returns the loss and grads given the input picture
        iterate = K.function([model.input], [loss, grads])

        # step size for gradient ascent
        step = 5.

        img_asc = np.array(img)
        # run gradient ascent for 20 steps
        for i in range(20):
            loss_value, grads_value = iterate([img_asc])
            img_asc += grads_value * step

        img_asc = img_asc[0]
        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))
        
    if layer_output.shape[3] >= 35:
        plot_x, plot_y = 6, 6
    elif layer_output.shape[3] >= 23:
        plot_x, plot_y = 4, 6
    elif layer_output.shape[3] >= 11:
        plot_x, plot_y = 2, 6
    else:
        plot_x, plot_y = 1, 2
    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))
    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')
    ax[0, 0].set_title('Input image')
    fig.suptitle('Input image and %s filters' % (layer_name,))
    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])
    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:
        if x == 0 and y == 0:
            continue
        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')
        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))

vis_img_in_filter()

